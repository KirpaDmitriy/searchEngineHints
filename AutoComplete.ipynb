{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoComplete.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Автодополнение запросов</h1>"
      ],
      "metadata": {
        "id": "36BJtJMsrqFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работать буду по следующей схеме: сначала создаю алгоритм, который строит структуру-индекс, которую затем уже можно использовать в подсказках для поиска. Индекс на больших текстах может строится долго, но его последующее использование будет быстро, оно сводится к обращению по ключу в словаре.\n",
        "Для начала применю следующий алгоритм: для каждого слова текста вычислю, какие другие слова чаще всего следуют за ним. Например, очевидно, что в большнстве случаев за словом \"так\" следует \"же\", за словом \"потому\" - \"что\", поэтому такая рекомендация имеет право на существование. Однако же она не учитывает предыдущий контекст, её работа зависит только от последнего введённого слова, это, явно, не соответствует тому, как строятся реальные высказывания (хотя поисковые запросы не очень длинны, в них эта модель может давать неплохие результаты). Модель можно расширить: Построить индекс по тому, какие слова чаще всего следуют за сочетаниями из двух, трех, четырех слов. Если мы обнаружили в тексте запроса какую-то последовательность из 4 слов, которая хранится у нас в индексе - скорее всего следующее введённое слово именно тем, которое мы храним в индексе, как наиболее часто встречающееся. Для построения таких 4-словных индексов нужны большие тексты, из которых можно достать сильные словосочетания, в которых можно почерпнуть надёжную статистику.\n",
        "Дополнительно отмечу, что решал задачу автодополнения, как задачу подбора одного слова - следующие слова можно подобрать после того, как было подобрано оно"
      ],
      "metadata": {
        "id": "2Qf38sZbAI14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yHG-ekDxQpO",
        "outputId": "3cc05959-1d74-44a9-d1ba-0dc07b0a6a04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " 'Александр Сергеевич Пушкин\\n',\n",
              " 'Евгений Онегин\\n',\n",
              " 'Роман в стихах\\n',\n",
              " '\\n',\n",
              " 'Pe€tri de vanite€ il avait encore plus de cette espe`ce d’orgueil qui fait avouer avec la me^me indiffe€rence les bonnes comme les mauvaises actions, suite d’un sentiment de supe€riorite€, peut-e^tre imaginaire.\\n',\n",
              " 'Tire€ d’une lettre particulie`re[1]He мысля гордый свет забавить,\\n',\n",
              " 'Вниманье дружбы возлюбя,\\n',\n",
              " 'Хотел бы я тебе представить\\n',\n",
              " 'Залог достойнее тебя,\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data = open('Onegin.txt').readlines()\n",
        "data[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_seq = {}\n",
        "\n",
        "for line in range(len(data)):\n",
        "  words = data[line].lower().split()\n",
        "  if line < len(data) - 1:\n",
        "    next_line = data[line + 1].lower().split()\n",
        "    if len(next_line) != 0:\n",
        "      words.append(next_line[0])\n",
        "  for word in range(len(words) - 1):\n",
        "    if not words[word].isalpha():\n",
        "      if not (words[word][0:len(words[word]) - 1].isalpha() and words[word][-1] == ','):\n",
        "        break\n",
        "      words[word] = words[word][0:len(words[word]) - 1]\n",
        "    if words[word] not in words_to_seq:\n",
        "      words_to_seq[words[word]] = {}\n",
        "    if words[word + 1] not in words_to_seq[words[word]]:\n",
        "      words_to_seq[words[word]][words[word + 1]] = 0\n",
        "    words_to_seq[words[word]][words[word + 1]] += 1\n",
        "words_to_seq['так']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OYb3M7L1iu1",
        "outputId": "9b78e07b-13ca-4580-b9c3-8caf096f7cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'бедный': 1,\n",
              " 'благочестия': 1,\n",
              " 'бледно,': 1,\n",
              " 'близко!..': 1,\n",
              " 'бури': 1,\n",
              " 'в': 1,\n",
              " 'ваша': 1,\n",
              " 'величавы,': 1,\n",
              " 'видно,': 1,\n",
              " 'возможно,': 1,\n",
              " 'воспитаньем,': 1,\n",
              " 'деревцо': 1,\n",
              " 'доверчива': 1,\n",
              " 'думал': 2,\n",
              " 'если': 1,\n",
              " 'же': 7,\n",
              " 'за': 1,\n",
              " 'зайчик': 1,\n",
              " 'и': 6,\n",
              " 'исправляется': 1,\n",
              " 'как': 1,\n",
              " 'ли': 1,\n",
              " 'ли,': 1,\n",
              " 'любит…': 1,\n",
              " 'люди': 1,\n",
              " 'медленно': 1,\n",
              " 'меня': 1,\n",
              " 'мило': 1,\n",
              " 'мой': 1,\n",
              " 'мысль': 1,\n",
              " 'на': 1,\n",
              " 'нас': 1,\n",
              " 'наше': 1,\n",
              " 'не': 1,\n",
              " 'непорочны,': 1,\n",
              " 'неприступны': 1,\n",
              " 'никого': 1,\n",
              " 'нимало': 1,\n",
              " 'одевает': 1,\n",
              " 'он': 2,\n",
              " 'они': 1,\n",
              " 'осмотрительны,': 1,\n",
              " 'подшутил': 1,\n",
              " 'полдень': 1,\n",
              " 'привык': 1,\n",
              " 'проповедовал': 1,\n",
              " 'пряником': 1,\n",
              " 'пчел': 1,\n",
              " 'равнодушна,': 1,\n",
              " 'смела?': 1,\n",
              " 'смиренно': 1,\n",
              " 'согласно…': 1,\n",
              " 'тихо,': 1,\n",
              " 'точно': 3,\n",
              " 'точны,': 1,\n",
              " 'ты,': 1,\n",
              " 'уж': 1,\n",
              " 'ужасно,': 1,\n",
              " 'умны,': 1,\n",
              " 'уносились': 1,\n",
              " 'что': 1,\n",
              " 'я,': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_continuation(initial_text):\n",
        "  initial_words = initial_text.lower().split()\n",
        "  last_word = initial_words[-1]\n",
        "  raw_recs = words_to_seq[last_word]\n",
        "  raw_recs[''] = 0\n",
        "  top5_keys = ['', '', '', '', '']\n",
        "  for rec in raw_recs:\n",
        "    for current_top in range(len(top5_keys)):\n",
        "      if raw_recs[top5_keys[current_top]] < raw_recs[rec]:\n",
        "        top5_keys[current_top] = rec\n",
        "        top5_keys = sorted(top5_keys, key=lambda x: raw_recs[x])\n",
        "        break\n",
        "  return top5_keys"
      ],
      "metadata": {
        "id": "kjMC0cDz4avE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_continuation('Сейчас он')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9mLZnJ45YLz",
        "outputId": "f8bc1da6-808f-4aa7-ba25-ee81cbf61a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['пел', 'мне', 'был', 'не', 'в']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Неплохие рекомендации, каждое слово кажется довольно естественным продолжением."
      ],
      "metadata": {
        "id": "oS45zv0oCwPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_continuation('Весна')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8WyLu4YCX8G",
        "outputId": "40d39861-e9e3-4253-f6ce-77f328947f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['живит', 'в', 'и', 'весна!', 'моих']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также попробовал алгоритм получения рекомендации, опирающийся на смысл слова. Для этого использовал модель word2vec русского языка, построенную по интернет-ресурсам. Применял её так: для каждого слова вычислял сумму векторов предшествующих ему в предложении слов так, чтобы наиболее \"далёкие\" (то есть расположенные в предложении дальше) слова имели меньший вес. Для слова получается набор векторов, построенных по предшествующим словам в разных предложениях. Усредняя эти вектора, получаю итоговый словарь, где ключи - слова текста, а значеия - 300-мерные представления, полученные на основании анализа предшествующих слов текста. Такой подход учитывает смысл слов, использует предыдущий контекст, а также в некоторой мере - частоту контекста (потому что в итоге вычисляется среднее значение по всем эмбеддингам)."
      ],
      "metadata": {
        "id": "YKJXPkW5DOJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01CDNtOTHs0Q",
        "outputId": "3b8d7a89-eadf-4074-ea8e-80afc7aa3be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3143551 sha256=81415171cb0ab7ffb8f60c530f289feb418a3fcc1637119e5816fea0cac6da40\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "ft = fasttext.load_model('cc.ru.300.bin')"
      ],
      "metadata": {
        "id": "AGI1_vDo3Dyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "data = ' '.join(list(filter(lambda el: (len(el) > 0) and (not el.isspace()), open('Onegin.txt').readlines()))).lower()\n",
        "data = re.split('[.!?\\n]', data)\n",
        "data = list(filter(lambda el: (len(el) > 0) and (not el.isspace()), data))\n",
        "data[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBU_cFaqNWXs",
        "outputId": "b0598de8-4705-4478-87fd-eb0ced9f6fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['александр сергеевич пушкин',\n",
              " ' евгений онегин',\n",
              " ' роман в стихах',\n",
              " ' pe€tri de vanite€ il avait encore plus de cette espe`ce d’orgueil qui fait avouer avec la me^me indiffe€rence les bonnes comme les mauvaises actions, suite d’un sentiment de supe€riorite€, peut-e^tre imaginaire',\n",
              " ' tire€ d’une lettre particulie`re[1]he мысля гордый свет забавить,',\n",
              " ' вниманье дружбы возлюбя,',\n",
              " ' хотел бы я тебе представить',\n",
              " ' залог достойнее тебя,',\n",
              " ' достойнее души прекрасной,',\n",
              " ' святой исполненной мечты,']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "emdedded_words = {}\n",
        "\n",
        "for line in data:\n",
        "  line = line.split()\n",
        "  for word in range(1, len(line)):\n",
        "    if line[word] not in emdedded_words:\n",
        "      emdedded_words[line[word]] = {'vecs': np.array([0.0] * ft.get_dimension()), 'count': 0}\n",
        "    prev_words_vecs = np.array([0.0] * ft.get_dimension())\n",
        "    for prev_word in range(word):\n",
        "      prev_words_vecs += ft.get_word_vector(line[prev_word]) * (2 ** (prev_word - word + 1))\n",
        "    emdedded_words[line[word]]['vecs'] += prev_words_vecs\n",
        "    emdedded_words[line[word]]['count'] += 1"
      ],
      "metadata": {
        "id": "balp_QDMO1NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for emb in emdedded_words:\n",
        "  emdedded_words[emb] = emdedded_words[emb]['vecs'] / emdedded_words[emb]['count']"
      ],
      "metadata": {
        "id": "mTFRb2VDTiif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(emdedded_words['сон'] - emdedded_words['луна']), np.linalg.norm(emdedded_words['сон'] - emdedded_words['солнце'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OpJ1VSXUMcb",
        "outputId": "d66c180a-7db7-46e2-ef12-7e3f5be146db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8601517312619978, 1.9304960047973203)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_k_nearest_neighbors(sentence, k):\n",
        "  sentence = sentence.split()\n",
        "  prev_words_vecs = np.array([0.0] * ft.get_dimension())\n",
        "  for prev_word in range(len(sentence)):\n",
        "    prev_words_vecs += ft.get_word_vector(sentence[prev_word]) * (2 ** (prev_word - len(sentence) + 1))\n",
        "  return list(zip(*sorted(list(map(lambda key: (np.linalg.norm(prev_words_vecs - emdedded_words[key]), key), emdedded_words.keys())))))[0][:k]\n",
        "\n",
        "print(get_k_nearest_neighbors('Ночь улица', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXrRjkt6U7lm",
        "outputId": "ae9a8f58-4f70-49d3-aaf2-a16515c4094c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('рядами', 'зимняя', 'стража', 'цветет', 'его:')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_k_nearest_neighbors('Сейчас он', 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZPled-vWqOQ",
        "outputId": "b3091bcb-8087-4a83-8b7f-4cbc9b76cecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('барщины', 'верил,', 'видит:', 'вслух,', 'говорил:')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказания получились правдоподобными, глаголы очень подходят. В целом, учитывя небольшой размер текста и его стиль (алгоритмы явно адаптируются под особенности автора, что кажется правильным), остальные слова также подходят в качестве завершения фразы."
      ],
      "metadata": {
        "id": "FotEOQMUH_84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь попытаюсь представить фразы исходного набора данных в виде векторов. Затем тем же способом буду строить вектор из запроса пользователя. По этому вектору буду искать наиболее близкие из уже имеющихся векторов."
      ],
      "metadata": {
        "id": "o6r6E-KLIb2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "data = ' '.join(list(filter(lambda el: (len(el) > 0) and (not el.isspace()), open('Onegin.txt').readlines()))).lower()\n",
        "expr = r'[^А-Яа-я .?!:,]'\n",
        "parser = re.compile(expr)\n",
        "data = re.sub(expr, '', data)\n",
        "data = re.split('[.!?]', data)\n",
        "data = list(filter(lambda el: (len(el) > 0) and (not el.isspace()), data))\n",
        "data[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoSD2hIj4Ewy",
        "outputId": "6c7b4a91-707e-457e-b472-29920cff8038"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['александр сергеевич пушкин евгений онегин роман в стихах                        ,     ,  ',\n",
              " '     мысля гордый свет забавить, вниманье дружбы возлюбя, хотел бы я тебе представить залог достойнее тебя, достойнее души прекрасной, святой исполненной мечты, поэзии живой и ясной, высоких дум и простоты но так и быть рукой пристрастной прими собранье пестрых глав, полусмешных, полупечальных, простонародных, идеальных, небрежный плод моих забав, бессонниц, легких вдохновений, незрелых и увядших лет, ума холодных наблюдений и сердца горестных замет',\n",
              " ' глава первая и жить торопится, и чувствовать спешит',\n",
              " ' князь вяземский  мой дядя самых честных правил, когда не в шутку занемог, он уважать себя заставил и лучше выдумать не мог',\n",
              " ' его пример другим наука но, боже мой, какая скука с больным сидеть и день и ночь, не отходя ни шагу прочь',\n",
              " ' какое низкое коварство полуживого забавлять, ему подушки поправлять, печально подносить лекарство, вздыхать и думать про себя: когда же черт возьмет тебя',\n",
              " '  так думал молодой повеса, летя в пыли на почтовых, всевышней волею зевеса наследник всех своих родных',\n",
              " ' друзья людмилы и руслана',\n",
              " ' с героем моего романа без предисловий, сей же час позвольте познакомить вас: онегин, добрый мой приятель, родился на брегах невы, где, может быть, родились вы или блистали, мой читатель там некогда гулял и я: но вреден север для меня',\n",
              " '  служив отличноблагородно, долгами жил его отец, давал три бала ежегодно и промотался наконец']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что предложения из романа довольно велики по сравнению с длиной типичного поискового запроса. Если их побить на более мелкие, получатся более похожие на запросы вектора."
      ],
      "metadata": {
        "id": "BryBje0BJ8HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word')"
      ],
      "metadata": {
        "id": "HGMGUhL93asm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expr = r'[^А-Яа-я ]'\n",
        "\n",
        "all_sentences = []\n",
        "\n",
        "parser = re.compile(expr)\n",
        "for sentence in data:\n",
        "  sentence = re.sub(expr, '', sentence)\n",
        "  all_sentences.append(sentence)\n",
        "all_sentences[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9epR9gst32be",
        "outputId": "0091926b-3489-468a-85d6-34146ca138b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['александр сергеевич пушкин евгений онегин роман в стихах                               ',\n",
              " '     мысля гордый свет забавить вниманье дружбы возлюбя хотел бы я тебе представить залог достойнее тебя достойнее души прекрасной святой исполненной мечты поэзии живой и ясной высоких дум и простоты но так и быть рукой пристрастной прими собранье пестрых глав полусмешных полупечальных простонародных идеальных небрежный плод моих забав бессонниц легких вдохновений незрелых и увядших лет ума холодных наблюдений и сердца горестных замет',\n",
              " ' глава первая и жить торопится и чувствовать спешит',\n",
              " ' князь вяземский  мой дядя самых честных правил когда не в шутку занемог он уважать себя заставил и лучше выдумать не мог',\n",
              " ' его пример другим наука но боже мой какая скука с больным сидеть и день и ночь не отходя ни шагу прочь',\n",
              " ' какое низкое коварство полуживого забавлять ему подушки поправлять печально подносить лекарство вздыхать и думать про себя когда же черт возьмет тебя',\n",
              " '  так думал молодой повеса летя в пыли на почтовых всевышней волею зевеса наследник всех своих родных',\n",
              " ' друзья людмилы и руслана',\n",
              " ' с героем моего романа без предисловий сей же час позвольте познакомить вас онегин добрый мой приятель родился на брегах невы где может быть родились вы или блистали мой читатель там некогда гулял и я но вреден север для меня',\n",
              " '  служив отличноблагородно долгами жил его отец давал три бала ежегодно и промотался наконец']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = tfidfvectorizer.fit(all_sentences)"
      ],
      "metadata": {
        "id": "8P7RRaij6pW1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_sentences = vectorizer.transform(all_sentences)\n",
        "embedded_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv7VWrK3ahrp",
        "outputId": "373f4845-8144-40a6-96e8-bc9a4fe07171"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1725x9316 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 21377 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "input_data = 'Бессмысленный и тусклый свет'\n",
        "\n",
        "similarities = list(sorted(enumerate(cosine_similarity(vectorizer.transform([input_data]), embedded_sentences)[0]), key=lambda el: el[1]))\n",
        "\n",
        "similar_sentences = []\n",
        "for el in similarities[len(similarities) - 5:len(similarities)]:\n",
        "  similar_sentences.append(all_sentences[el[0]])\n",
        "similar_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxmLCgkpaAg7",
        "outputId": "77e9bbdb-180f-419f-eb50-74deb75922be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' мой ваня моложе был меня мой свет а было мне тринадцать лет',\n",
              " ' и даже глупости смешной в тебе не встретишь свет пустой',\n",
              " ' свет решил что он умен и очень мил',\n",
              " ' довольно он морочил свет знаком он вам',\n",
              " ' что значит видеть свет']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Текст относительно невелик, поэтому предсказания не очень похожи на исходное предложение (хотя последнее созвучно по тематике). Исходный текст, например, не содержит слово \"бессмысленный\", то есть по факту идёт поиск по совпадению одного слова. Если построить вектора по огромному массиву текстов, можно получить результаты получше: будут попадаться похожие предложения, совпадения выведутся в результат."
      ],
      "metadata": {
        "id": "eKSpVrZNKf4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_words(words_list):\n",
        "  answer = ['']\n",
        "  for word in words_list:\n",
        "    for char in word:\n",
        "      if char.isalpha():\n",
        "        answer[-1] += char\n",
        "    answer.append('')\n",
        "  return list(filter(lambda w: len(w) > 0, answer))"
      ],
      "metadata": {
        "id": "Hwa-iK9aW7Yg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, чтобы сделать рекомендацию, из полученных похожих предложений вырежем лишнюю часть."
      ],
      "metadata": {
        "id": "fJT5lWa1WcQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recs = []\n",
        "\n",
        "for sentence in similar_sentences:\n",
        "  sentence = clean_words(sentence.lower().split())\n",
        "  word = 0\n",
        "  while word in range(len(sentence)):\n",
        "    if sentence[word] == input_data.split()[-1]:\n",
        "      break\n",
        "    word += 1\n",
        "  recs.append(' '.join(sentence[word + 1:]))\n",
        "list(filter(lambda el: len(el) > 0, recs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7frTsC-gyOd",
        "outputId": "739331d9-df1c-4f82-a13c-ac75ffa422c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['мой', 'ваня', 'моложе', 'был', 'меня', 'мой', 'свет', 'а', 'было', 'мне', 'тринадцать', 'лет']\n",
            "['и', 'даже', 'глупости', 'смешной', 'в', 'тебе', 'не', 'встретишь', 'свет', 'пустой']\n",
            "['свет', 'решил', 'что', 'он', 'умен', 'и', 'очень', 'мил']\n",
            "['довольно', 'он', 'морочил', 'свет', 'знаком', 'он', 'вам']\n",
            "['что', 'значит', 'видеть', 'свет']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['а было мне тринадцать лет',\n",
              " 'пустой',\n",
              " 'решил что он умен и очень мил',\n",
              " 'знаком он вам']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = 'и я любовь узнал душой с ее небесною отрадой с ее мучительной тоской'\n",
        "\n",
        "similarities = list(sorted(enumerate(cosine_similarity(vectorizer.transform([input_data]), embedded_sentences)[0]), key=lambda el: el[1]))\n",
        "\n",
        "similar_sentences = []\n",
        "for el in similarities[len(similarities) - 5:len(similarities)]:\n",
        "  similar_sentences.append(all_sentences[el[0]])\n",
        "similar_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKuW8PocM3Ps",
        "outputId": "a9d14abf-2dd3-489d-95bd-578631b02ac2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' не ты ль с отрадой и любовью слова надежды мне шепнул',\n",
              " ' кровь ее застыла',\n",
              " ' и где теперь ее сестра',\n",
              " ' я предан вам душой',\n",
              " ' ничто ее не занимает ее души не шевелит']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Текст того же автора дал очень правдоподобные результаты."
      ],
      "metadata": {
        "id": "GYv0DsQpNHPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пока что самые лучшие, на мой взгляд, результаты дал первый алгоритм - анализ частоты втречаемости комбинаций слов. Разовью идею, увеличивая количество слов, которые определяют рекомендуемое следующее. Построю 4 словаря-индекса, в них будут лежать сочетания от 1 до 4 слов (смысла брать больше для поискового запроса, полагаю, нет). Рекомендация будет идти сверху вниз по количеству слов в сочетании: сначала будет произведён поиск в словаре из 4-словных комбинаций последовательных слова исходного текста. Если что-то найдётся, скорее всего пользователь вводит именно эту фразу. Если в словаре ничего не нашлось, спускаемся ниже, в словарь с длинами комбинаций в 3 слова. И так далее до индекса, в котором хрантся пары последовательно идущих слов."
      ],
      "metadata": {
        "id": "xSlCL9_9aT2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = ' '.join(open('Пугачев.txt').readlines())"
      ],
      "metadata": {
        "id": "4uHFjJZvCgLd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = 'абвгдеёжзийклмнопртсухфцчшщьыьэюяabcdefghijklmnopqrstuvwxyz'\n",
        "stop_signs = '.!?;:'\n",
        "other_signs = ','\n",
        "\n",
        "def looks_like_word(text):\n",
        "  ok = False\n",
        "  for letter in alphabet:\n",
        "    if letter in text.lower():\n",
        "      ok = True\n",
        "      break\n",
        "  return ok\n",
        "\n",
        "def stop_separator(text):\n",
        "  sep = ''\n",
        "  for stop in stop_signs:\n",
        "    if stop in text.lower():\n",
        "      sep = stop\n",
        "      break\n",
        "  return sep\n",
        "\n",
        "sentences = ['']\n",
        "for token in data.split():\n",
        "  if looks_like_word(token):\n",
        "    sign_inside = stop_separator(token)\n",
        "    if len(sign_inside) == 0:\n",
        "      sentences[-1] += ''.join(token.split(other_signs)) + ' '\n",
        "    else:\n",
        "      mas = token.split(sign_inside)\n",
        "      for elem in range(len(mas)):\n",
        "        sentences[-1] += ''.join(mas[elem].split(other_signs)) + ' '\n",
        "        if elem + 1 < len(mas):\n",
        "          sentences.append('')\n",
        "  else:\n",
        "    if len(stop_separator(token)) != 0:\n",
        "      sentences.append('')\n",
        "\n",
        "sentences[10:60:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VePtrumeEWRe",
        "outputId": "bb416508-1da3-4fa4-e29d-2d06e70256e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' коего все затеи не от разума и воинского распорядка но от дерзости случая и удачи зависели ',\n",
              " ' Царская грамота ',\n",
              " ' Внутренние беспокойства ',\n",
              " ' течет к югу вдоль их цепи до того места где некогда положено было основание Оренбургу и где теперь находится Орская крепость ',\n",
              " ' Его течение быстро ',\n",
              " ' Они зимовали на ее берегах в то время еще покрытых лесом и безопасных по своему уединению ',\n",
              " ' казаки стали получать жен из татарских улусов ',\n",
              " ' Живя набегами окруженные неприязненными племенами казаки чувствовали необходимость в сильном покровительстве и в царствование Михаила Федоровича послали от себя в Москву просить государя чтоб он принял их под свою высокую руку ',\n",
              " ' Шах жаловался царю ',\n",
              " ' а на Яик посланы были стрельцы в последствии времени составившие с казаками одно племя ']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clear_sentences = []\n",
        "\n",
        "for sentence in sentences:\n",
        "  clear_sentences.append('')\n",
        "  for symbol in sentence:\n",
        "    if symbol.isalpha() or symbol == ' ':\n",
        "      clear_sentences[-1] += symbol.lower()\n",
        "\n",
        "clear_sentences[10:60:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fMsz2a7Ix64",
        "outputId": "f38bff0f-c377-4a3d-b61f-00979c4acd16"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' коего все затеи не от разума и воинского распорядка но от дерзости случая и удачи зависели ',\n",
              " ' царская грамота ',\n",
              " ' внутренние беспокойства ',\n",
              " ' течет к югу вдоль их цепи до того места где некогда положено было основание оренбургу и где теперь находится орская крепость ',\n",
              " ' его течение быстро ',\n",
              " ' они зимовали на ее берегах в то время еще покрытых лесом и безопасных по своему уединению ',\n",
              " ' казаки стали получать жен из татарских улусов ',\n",
              " ' живя набегами окруженные неприязненными племенами казаки чувствовали необходимость в сильном покровительстве и в царствование михаила федоровича послали от себя в москву просить государя чтоб он принял их под свою высокую руку ',\n",
              " ' шах жаловался царю ',\n",
              " ' а на яик посланы были стрельцы в последствии времени составившие с казаками одно племя ']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_words_combinations = {}\n",
        "\n",
        "for sentence in clear_sentences:\n",
        "  sentence = sentence.split()\n",
        "  for word in range(2, len(list(filter(lambda w: len(w) > 0, sentence)))):\n",
        "    two_words = sentence[word - 2] + sentence[word - 1]\n",
        "    if two_words not in two_words_combinations:\n",
        "      two_words_combinations[two_words] = {}\n",
        "    if sentence[word] not in two_words_combinations[two_words]:\n",
        "      two_words_combinations[two_words][sentence[word]] = 0\n",
        "    two_words_combinations[two_words][sentence[word]] += 1\n",
        "\n",
        "two_words_combinations['внем']"
      ],
      "metadata": {
        "id": "wYjPYX7IJgZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cd5012-ba52-4889-f619-17c6f36fa9ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'атаману': 1,\n",
              " 'было': 2,\n",
              " 'веселия': 1,\n",
              " 'и': 1,\n",
              " 'находилось': 1,\n",
              " 'находится': 1,\n",
              " 'начальник': 1,\n",
              " 'робость': 1,\n",
              " 'собрано': 1,\n",
              " 'убежища': 1,\n",
              " 'уже': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Появляются уже более сложные конструкции: \"пускались в море\", \"в разных местах\", \"в состоянии были\"."
      ],
      "metadata": {
        "id": "QD5BlBRgqfpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n_words_combinations(n):\n",
        "  words_combinations = {}\n",
        "\n",
        "  for sentence in clear_sentences:\n",
        "    sentence = sentence.split()\n",
        "    for word in range(n, len(list(filter(lambda w: len(w) > 0, sentence)))):\n",
        "      prev_words = ''\n",
        "      for delta in range(1, n + 1):\n",
        "        prev_words += sentence[word - (n + 1 - delta)]\n",
        "      if prev_words not in words_combinations:\n",
        "        words_combinations[prev_words] = {}\n",
        "      if sentence[word] not in words_combinations[prev_words]:\n",
        "        words_combinations[prev_words][sentence[word]] = 0\n",
        "      words_combinations[prev_words][sentence[word]] += 1\n",
        "  \n",
        "  return words_combinations\n",
        "n_words_combinations(4)['россииохраняяюжныеее']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ow1ebBVsu6b",
        "outputId": "54f49ba3-7faa-4f1e-c2d6-92b697386d38"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'границы': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преимущество такого анализа в том, что не нужно производить сравнения векторов, высчитывать расстояния между ними, сортировать, то есть тратить время. Процесс построения происходит до, того, как пользователь отправит запрос."
      ],
      "metadata": {
        "id": "VwYDTrdjYDmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Такой подход к тому же даёт возможность подсказывать пользователю, где совершены опечатки в запросе (если идти с начала запроса и сравнивать слова пользователя с наиболее часто встречающимися словами в данной комбинации через редакторское расстояние, то слабо отличающиеся слова можно заменсять на те, что есть в словаре, скорее всего пользователь в них ошибся)."
      ],
      "metadata": {
        "id": "XJSNdyNBsBRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно, думаю, что лучше дообучивать любой из приведённых алгоритмов на наборах, которые генерирует сам пользователь. Манера разгоровора для каждого уникальна, нужно уметь подстраиваться под речь конкретного пользователя, чтобы программа вела себя естественно."
      ],
      "metadata": {
        "id": "4iCPcmDDVA0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также испытал другой подход: высчитывал не частоту употребления слов друг с другом, а средние расстояния между ними, вычисленные, как разности индексов."
      ],
      "metadata": {
        "id": "WmhPS9hVh2G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_distances = {}\n",
        "for sentence in clear_sentences:\n",
        "  sentence = list(filter(lambda w: len(w) > 0, sentence.split()))\n",
        "  for i in range(len(sentence)):\n",
        "    for j in range(i + 1, len(sentence)):\n",
        "      word1, word2 = sentence[i], sentence[j]\n",
        "      if word1 not in words_distances:\n",
        "        words_distances[word1] = {}\n",
        "      if word2 not in words_distances:\n",
        "        words_distances[word2] = {}\n",
        "      if word2 not in words_distances[word1]:\n",
        "        words_distances[word1][word2] = [None, 0]\n",
        "      if word1 not in words_distances[word2]:\n",
        "        words_distances[word2][word1] = [None, 0]\n",
        "      words_distances[word1][word2][0] = abs(i - j)\n",
        "      words_distances[word1][word2][1] += 1\n",
        "      words_distances[word2][word1][0] = abs(i - j)\n",
        "      words_distances[word2][word1][1] += 1\n",
        "\n",
        "for word1 in words_distances:\n",
        "  for word2 in words_distances[word1]:\n",
        "    words_distances[word1][word2] = words_distances[word1][word2][0] / words_distances[word1][word2][1]\n",
        "\n",
        "closest = {}\n",
        "for word1 in words_distances:\n",
        "  top5_closest = list(sorted(words_distances[word1].keys(),\n",
        "                             key=lambda word2: words_distances[word1][word2]))[0:5]\n",
        "  closest[word1] = top5_closest"
      ],
      "metadata": {
        "id": "zna7OXiIaAzJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_distances['благодеяния']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMQXETNRhPTU",
        "outputId": "c67cb974-3ef7-4501-e5cf-bb0616db99c0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'воздадим': 14.0,\n",
              " 'же': 15.0,\n",
              " 'за': 2.5,\n",
              " 'к': 7.0,\n",
              " 'любовь': 8.0,\n",
              " 'матернюю': 9.0,\n",
              " 'мы': 13.0,\n",
              " 'нам': 0.5,\n",
              " 'несказанные': 2.0,\n",
              " 'сии': 4.0,\n",
              " 'твои': 3.0,\n",
              " 'твою': 10.0,\n",
              " 'тебе': 12.0,\n",
              " 'чем': 16.0}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest['благодеяния']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC0-6C-Khk6A",
        "outputId": "9b436019-dd84-4baf-e3fe-6d8c1e57b34f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['нам', 'несказанные', 'за', 'твои', 'сии']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказания довольно хороши."
      ],
      "metadata": {
        "id": "0pr1ropQiEuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Помимо этого, можно применить ML вещи: сети, классические алгоритмы."
      ],
      "metadata": {
        "id": "NyNqgjHFZcpJ"
      }
    }
  ]
}